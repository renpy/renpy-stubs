import ast
import tokenize
from typing import Generator, Iterator

def fix_octal_numbers(tokens: Iterator[tokenize.TokenInfo]) -> Generator[tokenize.TokenInfo, None, None]: ...
def fix_spaceship(tokens: Iterator[tokenize.TokenInfo]) -> Generator[tokenize.TokenInfo, None, None]: ...
def fix_backtick_repr(tokens: Iterator[tokenize.TokenInfo]) -> Generator[tokenize.TokenInfo, None, None]: ...
def fix_print(line: list[tokenize.TokenInfo]) -> list[tokenize.TokenInfo]: ...
def fix_raise(line: list[tokenize.TokenInfo]) -> list[tokenize.TokenInfo]: ...
def fix_lines(tokens: Iterator[tokenize.TokenInfo]) -> Generator[tokenize.TokenInfo, None, None]: ...
def fix_tokens(source: str) -> str: ...

class ReorderGlobals(ast.NodeTransformer):
    globals: set[str]
    def __init__(self) -> None: ...
    def visit_Global(self, node: ast.Global) -> ast.Pass: ...
    def visit_FunctionDef(self, node: ast.FunctionDef) -> ast.FunctionDef: ...

reorder_globals: ReorderGlobals

def fix_ast(tree: ast.AST) -> ast.AST: ...
